{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_data(data_file, train_idx_file, test_idx_file):\n",
    "    \"\"\"\n",
    "    Load train and test data from data_file\n",
    "    Returns:\n",
    "        X_train, Y_train, X_test, Y_test\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data\n",
    "    def conv(item):\n",
    "        return item.split(\":\")[1] if \":\" in item else item\n",
    "\n",
    "    data = np.l(data_file, converters=conv)\n",
    "    print(f\"\\n Data shape: {data.shape}\")\n",
    "    \n",
    "    # Load index\n",
    "    train_idx = np.loadtxt(train_idx_file, dtype=\"int\", delimiter=\",\")\n",
    "    test_idx = np.loadtxt(test_idx_file, dtype=\"int\", delimiter=\",\")\n",
    "    \n",
    "    X_train, Y_train = data[train_idx, 1:], data[train_idx, 0]\n",
    "    X_test, Y_test = data[test_idx, 1:], data[test_idx, 0]\n",
    "\n",
    "    # Reassign value for classes:\n",
    "    \n",
    "    print(f\"\\nX_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, Y_train shape: {Y_test.shape}\\n\")\n",
    "    return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f2541bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data shape: (683, 11)\n",
      "\n",
      "X_train shape: (546, 10), Y_train shape: (546,)\n",
      "X_test shape: (137, 10), Y_train shape: (137,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cancer_file = \"hw4_data/breast-cancer_scale\"\n",
    "cancer_train_indices_file = \"hw4_data/breast-cancer_train_indices.txt\"\n",
    "cancer_test_indices_file = \"hw4_data/breast-cancer_test_indices.txt\"\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_data(cancer_file, cancer_train_indices_file, cancer_test_indices_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f1ce1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading: hw4_data/sonar_scale\n"
     ]
    }
   ],
   "source": [
    "# Load data file\n",
    "data_file = 'hw4_data/sonar_scale'\n",
    "print(f\"\\nLoading: {data_file}\")\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "max_feature = 0\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if not parts:\n",
    "            continue\n",
    "        \n",
    "        y_list.append(int(float(parts[0])))\n",
    "        \n",
    "        features = {}\n",
    "        for item in parts[1:]:\n",
    "            idx, val = item.split(':')\n",
    "            idx = int(idx) - 1\n",
    "            features[idx] = float(val)\n",
    "            max_feature = max(max_feature, idx)\n",
    "        X_list.append(features)\n",
    "\n",
    "# Convert to arrays\n",
    "n_samples = len(y_list)\n",
    "n_features = max_feature + 1\n",
    "X = np.zeros((n_samples, n_features))\n",
    "for i, features in enumerate(X_list):\n",
    "    for idx, val in features.items():\n",
    "        X[i, idx] = val\n",
    "y = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "467564e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train/test indices\n",
    "train_idx = np.loadtxt('hw4_data/sonar_train_indices.txt', dtype=int, delimiter=',')\n",
    "test_idx = np.loadtxt('hw4_data/sonar_test_indices.txt', dtype=int, delimiter=',')\n",
    "\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1323000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_file = \"hw4_data/sonar_scale\"\n",
    "sonar_train_indices_file = \"hw4_data/sonar_train_indices.txt\"\n",
    "sonar_test_indices_file = \"hw4_data/sonar_test_indices.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f859131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Cs = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# \"poly\": Polynominal, \"rbf\": RBF\n",
    "class SupportVectorClassifier:\n",
    "    def __init__(self, loss: str = \"hinge\",\n",
    "                 penalty: str = \"l2\",\n",
    "                 kernel: str = \"linear\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Will use LinearSVC if kernel = \"linear\"\n",
    "        \"\"\"\n",
    "        self.loss = loss\n",
    "        self.penalty = penalty\n",
    "        self.kernel = kernel\n",
    "    \n",
    "\n",
    "    def create_model(self, C):\n",
    "        model = None\n",
    "        if self.kernel == \"linear\":\n",
    "            model = LinearSVC(penalty=self.penalty, loss = self.loss, C=C, random_state=42)\n",
    "        else:\n",
    "            model = SVC(kernel=self.kernel, C=C)\n",
    "\n",
    "        # model = LogisticRegression(C=C, max_iter=1000, penalty='l2', solver='lbfgs')\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def kfold_cross_validation(self, X_train, Y_train, k, Cs):\n",
    "        kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        validation_err = []\n",
    "        training_err = []\n",
    "\n",
    "        for C in Cs:\n",
    "            \n",
    "            val_errors = []\n",
    "            training_errors = []\n",
    "\n",
    "            for train_idx, val_idx in kfold.split(X_train):\n",
    "\n",
    "                # classifier = self.create_model(C)\n",
    "                \n",
    "                X_train_split, Y_train_split = X_train[train_idx, :], Y_train[train_idx]\n",
    "                X_val_split, Y_val_split = X_train[val_idx, :], Y_train[val_idx]\n",
    "\n",
    "                model = self.train(X_train_split, Y_train_split, C)\n",
    "                # classifier.fit(X_train_split, Y_train_split)\n",
    "                \n",
    "                # training_errors.append(1 - classifier.score(X_train_split, Y_train_split))\n",
    "                # val_errors.append(1 - classifier.score(X_val_split, Y_val_split))\n",
    "                \n",
    "                predict = model.predict(X_train_split)\n",
    "                training_errors.append(1 - accuracy_score(Y_train_split, predict))\n",
    "                val_errors.append(self.eval(model, X_val_split, Y_val_split))\n",
    "            \n",
    "            validation_err.append(np.mean(val_errors))\n",
    "            training_err.append(np.mean(training_errors))\n",
    "\n",
    "\n",
    "        best_C = Cs[np.argmin(validation_err)]\n",
    "\n",
    "        return training_err, validation_err, best_C\n",
    "    \n",
    "\n",
    "    def train(self, X_train, Y_train, C):\n",
    "        classifier = self.create_model(C)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        return classifier\n",
    "    \n",
    "\n",
    "    def eval(self, model, X_test, Y_test):\n",
    "        error_rate = 1- model.score(X_test, Y_test)\n",
    "        return error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b5f4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ff35f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.0279260176768207), np.float64(0.026096403753700193), np.float64(0.026097453446140294), np.float64(0.025182121638359978), np.float64(0.03479520500493356)]\n",
      "5-fold cross-validation:\n",
      "        C  Train error  Val error\n",
      "0     0.1     0.027926   0.034746\n",
      "1     1.0     0.026096   0.032927\n",
      "2    10.0     0.026097   0.038399\n",
      "3   100.0     0.025182   0.040250\n",
      "4  1000.0     0.034795   0.045738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/legiakhanh/Documents/ML633/Logistic-Regression-and-SVM/.venv/lib/python3.13/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svc = SupportVectorClassifier(kernel=\"linear\")\n",
    "train_err, val_err, best_C = svc.kfold_cross_validation(X_train, Y_train, 5, Cs)\n",
    "print(train_err)\n",
    "df = pd.DataFrame({\"C\": Cs,\n",
    "                   \"Train error\": train_err,\n",
    "                   \"Train error\": train_err,\n",
    "                   \"Val error\": val_err})\n",
    "\n",
    "print(f\"5-fold cross-validation:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0f3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file:\n",
      "\thw4_data/covtype.data\n",
      "\thw4_data/covtype_train_indices.txt\n",
      "\thw4_data/covtype_test_indices.txt\n",
      "X shape: (581012, 54)\n",
      "Y shape: (581012,)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "covtype_file = \"hw4_data/covtype.data\"\n",
    "covtype_train_indices_file = \"hw4_data/covtype_train_indices.txt\"\n",
    "covtype_test_indices_file = \"hw4_data/covtype_test_indices.txt\"\n",
    "\n",
    "def load_covtype(filename, file_indices_train, file_indices_test):\n",
    "    data = np.loadtxt(filename, delimiter=\",\")\n",
    "    X = data[:, :-1]\n",
    "    Y =data[:, -1]\n",
    "\n",
    "    train_indices = np.loadtxt(file_indices_train, dtype=\"int\", delimiter=\",\")\n",
    "    test_indices = np.loadtxt(file_indices_test, dtype=\"int\", delimiter=\",\")\n",
    "\n",
    "    X_train, Y_train = X[train_indices, :], Y[train_indices]\n",
    "    X_test, Y_test = X[test_indices, :], Y[test_indices]\n",
    "\n",
    "    print(\"Load files:\")\n",
    "    print(f\"\\t{filename}\\n\\t{file_indices_train}\\n\\t{file_indices_test}\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"Y shape: {Y.shape}\")\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_covtype(covtype_file, covtype_train_indices_file, covtype_test_indices_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def data_preprocessing(X, method:str):\n",
    "    if method == \"normalization\":\n",
    "        X_normalized = preprocessing.normalize(X, norm=\"l2\", axis=1)\n",
    "        return X_normalized\n",
    "    \n",
    "    if method == \"rescale\":\n",
    "        minmax_scaler = preprocessing.MinMaxScaler(X) # default range (0, 1)\n",
    "        X_scaled = minmax_scaler.fit_transform(X)\n",
    "        return X_scaled\n",
    "\n",
    "    if method == \"standardization\":\n",
    "        standard_scaler = preprocessing.StandardScaler()\n",
    "        X_standardized = standard_scaler.fit_transform(X=X)\n",
    "        return X_standardized\n",
    "    \n",
    "    print(\"No available data preprocessing method!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f253b7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9999999999999999)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2],\n",
    "              [2, 3],\n",
    "              [3, 4]])\n",
    "\n",
    "a = preprocessing.normalize(a)\n",
    "a[0, :].T @ a[0, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
